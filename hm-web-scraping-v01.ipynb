{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def request_soup(url_link):    \n",
    "    headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0'}    \n",
    "    page = requests.get( url, headers = headers)\n",
    "    soup_obj = BeautifulSoup(page.text, 'html.parser')\n",
    "    return( soup_obj )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Requesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Home Page Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all products url\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# headers for request\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0'}\n",
    "\n",
    "# requesting\n",
    "page = requests.get(url=url, headers=headers)\n",
    "\n",
    "# instatiating bs4 object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding load more products element\n",
    "p = soup.find('div', class_='load-more-products')\n",
    "\n",
    "# all products\n",
    "all_products = int(p.find('h2').get('data-total'))\n",
    "\n",
    "# products per page\n",
    "products_per_page = int(p.find('h2').get('data-items-shown'))\n",
    "\n",
    "# rounding up numer of pages needed for web scraping\n",
    "total_pages = np.ceil(all_products/products_per_page)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  All products in Home Page Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a page with all products\n",
    "url_all_prods = url + '?&offset=0&page-size={}'.format(int(total_pages*products_per_page))\n",
    "\n",
    "all_prods = requests.get(url = url_all_prods, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(all_prods.text, 'html.parser')#.get('li', class_='product-item')\n",
    "\n",
    "# soup.find('li', class_ = 'product-item').find('a').get('href') #.get('item-link')  #.get('item-link') #, class_ = 'item-link')\n",
    "# all find all products listed in homepage\n",
    "products = soup.find_all('li', class_='product-item')\n",
    "\n",
    "# get link to all projects\n",
    "home_links = ['https://www2.hm.com' + link.find('a').get('href') for link in products ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  All products in Each Product Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulting list of all products to scrap\n",
    "links = []\n",
    "\n",
    "for link in home_links:\n",
    "    # scrap each product in home page list\n",
    "    single_product = requests.get(link, headers = headers)\n",
    "    soup = BeautifulSoup(single_product.text, 'html.parser')\n",
    "\n",
    "    # gets the links to all products listed in a page\n",
    "    products_ul = soup.find('ul', class_='inputlist clearfix')\n",
    "    products = products_ul.find_all('a')\n",
    "\n",
    "    links_ul = []\n",
    "    links_ul = [ 'https://www2.hm.com' + item.get('href') for item in products]\n",
    "    links.extend(links_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining base dataframe\n",
    "df_prods = pd.DataFrame(columns=['product_id', 'color', 'style_id', 'color_id', 'link'])\n",
    "\n",
    "for link in home_links:\n",
    "    \n",
    "    # scrap each product in home page list\n",
    "    single_product = requests.get(link, headers = headers)\n",
    "    soup = BeautifulSoup(single_product.text, 'html.parser')\n",
    "\n",
    "    # scrap all products listed in a page\n",
    "    products_ul = soup.find('ul', class_='inputlist clearfix')\n",
    "    products = products_ul.find_all('a')\n",
    "\n",
    "    for product in products:\n",
    "        \n",
    "        #product it\n",
    "        product_id = product.get('data-articlecode')\n",
    "\n",
    "        # color\n",
    "        color = product.get('data-color')\n",
    "        \n",
    "        # style id\n",
    "        style_id = product_id[:-3]\n",
    "        \n",
    "        # style id\n",
    "        color_id = product_id[-3:]\n",
    "\n",
    "        # link\n",
    "        link = 'https://www2.hm.com/en_us/productpage.{}.html'.format(product_id)\n",
    "\n",
    "        df_temp = pd.DataFrame( {'product_id': product_id, 'color': color, 'style_id' :style_id, 'color_id' : color_id, 'link': link}, index = [0] )\n",
    "        \n",
    "        df_prods = pd.concat([df_prods, df_temp], axis = 0)\n",
    "\n",
    "\n",
    "df_prods.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_prods.drop_duplicates('product_id',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www2.hm.com/en_us/productpage.1024256001.html'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = request_soup(df_prods.link[0])\n",
    "df_prods.link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find('div', class_='ProductDescription-module--productDescription__2mqXe')\n",
    "soup.find('div', class_='details parbase')\n",
    "soup_text = soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get( df_prods.link[0], headers = headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "\n",
    "# soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "try to use lxml, if doesn't work use selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THIS FOR REFERENCE IN CASE NEEDED LATER\n",
    "\n",
    "# soup.find_all('a', class_='swatch')#[0].get('title')\n",
    "# elements = soup.find_all('a', class_='swatch')\n",
    "\n",
    "# df = pd.DataFrame(columns=['product_id', 'color', 'style_id', 'color_id', 'link'])\n",
    "\n",
    "# for element in elements:\n",
    "#     # article number\n",
    "#     product_id = element.get('href').split('.')[1]\n",
    "    \n",
    "#     # color\n",
    "#     color = element.get('title')\n",
    "\n",
    "#     # style id\n",
    "#     style_id = product_id[:-3]\n",
    "    \n",
    "#     # style id\n",
    "#     color_id = product_id[-3:]\n",
    "\n",
    "#     # link\n",
    "#     link = 'https://www2.hm.com/en_us/productpage.{}.html'.format(product_id)\n",
    "\n",
    "#     df_temp = pd.DataFrame( {'product_id': product_id, 'color': color, 'style_id' :style_id, 'color_id' : color_id, 'link': link}, index = [0] )\n",
    "    \n",
    "#     df = pd.concat([df, df_temp], axis = 0)\n",
    "\n",
    "# df.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www2.hm.com/en_us/productpage.1024256001.html'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Art. No.,color,style_id,color_id,link,Fit,Composition,Price,date,texts,Cotton,Polyester,Elastane,Elasterell-P,Modal,Viscose\n",
    "# pd.DataFrame( {'href': h_ref, 'color': color}, index = [0] )\n",
    "\n",
    "df.link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('ul', class_=\"inputlist clearfix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e351bda13fd12210c56cd25328508007dc56e1370bfddb216f0f5bba4101204e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('web_scraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
